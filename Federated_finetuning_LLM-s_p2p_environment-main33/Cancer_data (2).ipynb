{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D2M3bbhXBb5"
      },
      "outputs": [],
      "source": [
        "pip install pandas pyarrow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNfLSjKYXBZC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.parquet' with the path to your Parquet file\n",
        "parquet_file1 = '/content/train-00000-of-00001-10facf3aec73943e (1).parquet'\n",
        "parquet_file2 = '/content/validation-00000-of-00001-c5bd4e9739aa242a (1).parquet'\n",
        "parquet_file3 = '/content/test-00000-of-00001-80772f3c893882f0 (1).parquet'\n",
        "\n",
        "# Read the Parquet file into a pandas DataFrame\n",
        "df1 = pd.read_parquet(parquet_file1)\n",
        "df2 = pd.read_parquet(parquet_file2)\n",
        "df3 = pd.read_parquet(parquet_file3)\n",
        "\n",
        "df = pd.merge(df1,df2)\n",
        "df = pd.merge(df,df3)\n",
        "# Replace 'output_file.csv' with the desired CSV output file name\n",
        "csv_file = 'data.csv'\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "df.to_csv(csv_file, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAZWXlcKXBWb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "df['input'] = df['input'].str[:400]\n",
        "\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "df = df[['input', 'label']]\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'Class' column to numerical values\n",
        "df['label'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Save the train and test DataFrames to separate CSV files\n",
        "train_csv_file = 'train_file_cancer_data_fina.csv'\n",
        "test_csv_file = 'test_file_cancer_data_fina.csv'\n",
        "\n",
        "train_data.to_csv(train_csv_file, index=False)\n",
        "test_data.to_csv(test_csv_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-S2O-DGXBTk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmzS0ZoZg0oz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHpvdScog0mf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN3JGdwCg0j2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXLGcanLg0hP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4dWy2odg0ec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3oRPnUCg0bv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D7_5X2ag0ZU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkX1MsHRg0WS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO9TUkl2g0T7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHG9lkJ0g0RF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9o9OtXCg0Om"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki5ZhSG7g0MP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U70z9asb_OCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYa5u2CF_N_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsGDkqxv_N8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3u6vfQV_N5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GDbOWUm_N2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CX4lCsUg_NzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdKbygUp_NwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFplEMtF_Ntn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4NzHBknb_NqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3GnrIm8j_NnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C11URVsP_Nj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0c1Vrcb_NhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQWFxDyG_k9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8Wx6sXh_k6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbVEMDwi_k34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSur4i5c_k1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdceDXWo_kyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PVT8ehBe_kvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWpWCDuM_ksc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TuYAY5Rs_kpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GoLo-fc_kms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8EWcbVzt_kj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLwoNxpe_kgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1k862da3_kdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4D7xHJB_kat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwoJYgtS_kX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NeLicACk_kUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfmyxlsL_kR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mI4UVXh8_kOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "969HkMh6_kLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZGXDHao_kJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ySzfDRW_kGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4fr6ZF9_kDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZYvkg511_kAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dAENmE-9_j9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JngttmUW_j3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ggw7eaQ3_j0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2dJuvabr_jr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lSd1s1kl_jpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DiCez5Ew_jkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Sl7Yb5f_jht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t9pY_8FU_jfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYU4SN73_jcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U9_6AX1g_jWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH0f4SGKUoou"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('/content/finalSentimentdata2.csv')\n",
        "df = df[['text', 'sentiment']]\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'Class' column to numerical values\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
        "X = df.drop('sentiment', axis=1)  # Replace 'target_column' with your target column name\n",
        "y = df['sentiment']\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate the majority and minority classes\n",
        "df_positive = df[df.sentiment == 2]\n",
        "df_negative = df[df.sentiment == 0]\n",
        "df_neutral = df[df.sentiment == 1]\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_positive_upsampled = resample(df_positive,\n",
        "                                 replace=True,\n",
        "                                 n_samples=len(df_negative),  # Match number in negative class\n",
        "                                 random_state=123)\n",
        "\n",
        "# Combine with other classes\n",
        "df_upsampled = pd.concat([df_positive_upsampled, df_negative, df_neutral])\n",
        "df_upsampled.to_csv(\"finals_medicals.csv\")\n",
        "# num_unique_labels = csv_file['medical_specialty'].nunique()\n",
        "# print(f\"Number of unique labels in the column: {num_unique_labels}\")\n",
        "\n",
        "# Step 2: Split the data into train and test sets\n",
        "# You can adjust the test_size parameter to control the ratio\n",
        "print(df_upsampled)\n",
        "df_negative_downsampled = resample(df_negative,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_positive),  # Match number in positive class\n",
        "                                   random_state=123)\n",
        "\n",
        "# Combine with other classes\n",
        "df_downsampled = pd.concat([df_positive, df_negative_downsampled, df_neutral])\n",
        "df_upsampled = df_upsampled.sample(frac=1).reset_index(drop=True)\n",
        "df_downsampled = df_downsampled.sample(frac=1).reset_index(drop=True)\n",
        "df = pd.concat([df_upsampled,df_downsampled,df_negative])\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Save the train and test DataFrames to separate CSV files\n",
        "train_csv_file = 'train_file11.csv'\n",
        "test_csv_file = 'test_file11.csv'\n",
        "\n",
        "train_data.to_csv(train_csv_file, index=False)\n",
        "test_data.to_csv(test_csv_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6pldPNdUolm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfzUSyUyUoi1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gO5d7P2UogI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm8GoKRdUodi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkuBk-1aUoa7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3CZYD7wUoX1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnZ0gg-cqTJV",
        "outputId": "6ad16206-6511-4858-b67f-aab8124de005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   text  sentiment\n",
            "2178  its better to read quality stuff rather then w...          2\n",
            "1527  from our perspective he is at another level wh...          2\n",
            "1593  dealing with is not only about physical health...          2\n",
            "1341  welcome back and good news on the covid test l...          2\n",
            "480   is a congregation of traitors they were succes...          2\n",
            "...                                                 ...        ...\n",
            "3067  my eyebrows cannot take this coronavirus any l...          1\n",
            "3069  the fact that everyone is panicking over the c...          1\n",
            "3070  i love this my fear is the constant barraging ...          1\n",
            "3076  this is actually ridiculous i hope everyone is...          1\n",
            "3079  do not wana spread panic but this my friends i...          1\n",
            "\n",
            "[2335 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('/content/finalSentimentdata2.csv')\n",
        "df = df[['text', 'sentiment']]\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'Class' column to numerical values\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
        "X = df.drop('sentiment', axis=1)  # Replace 'target_column' with your target column name\n",
        "y = df['sentiment']\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate the majority and minority classes\n",
        "df_positive = df[df.sentiment == 2]\n",
        "df_negative = df[df.sentiment == 0]\n",
        "df_neutral = df[df.sentiment == 1]\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_positive_upsampled = resample(df_positive,\n",
        "                                 replace=True,\n",
        "                                 n_samples=len(df_negative),  # Match number in negative class\n",
        "                                 random_state=123)\n",
        "\n",
        "# Combine with other classes\n",
        "df_upsampled = pd.concat([df_positive_upsampled, df_negative, df_neutral])\n",
        "df_upsampled.to_csv(\"finals_medicals.csv\")\n",
        "# num_unique_labels = csv_file['medical_specialty'].nunique()\n",
        "# print(f\"Number of unique labels in the column: {num_unique_labels}\")\n",
        "\n",
        "# Step 2: Split the data into train and test sets\n",
        "# You can adjust the test_size parameter to control the ratio\n",
        "print(df_upsampled)\n",
        "df_negative_downsampled = resample(df_negative,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_positive),  # Match number in positive class\n",
        "                                   random_state=123)\n",
        "\n",
        "# Combine with other classes\n",
        "df_downsampled = pd.concat([df_positive, df_negative_downsampled, df_neutral])\n",
        "df_upsampled = df_upsampled.sample(frac=1).reset_index(drop=True)\n",
        "df_downsampled = df_downsampled.sample(frac=1).reset_index(drop=True)\n",
        "df = pd.concat([df_upsampled,df_downsampled,df_negative])\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Save the train and test DataFrames to separate CSV files\n",
        "train_csv_file = 'train_file11.csv'\n",
        "test_csv_file = 'test_file11.csv'\n",
        "\n",
        "train_data.to_csv(train_csv_file, index=False)\n",
        "test_data.to_csv(test_csv_file, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fu3s4Eh1aJE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiY3TkVz1aFu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1PuJu7G1aDE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "csv_file = pd.read_csv('/content/finalSentimentdata2.csv')\n",
        "csv_file = csv_file[[\"sentiment\", \"text\"]]\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'Class' column to numerical values\n",
        "csv_file['sentiment'] = label_encoder.fit_transform(csv_file['sentiment'])\n",
        "\n",
        "csv_file.to_csv(\"finals_medicals.csv\")\n",
        "# num_unique_labels = csv_file['medical_specialty'].nunique()\n",
        "# print(f\"Number of unique labels in the column: {num_unique_labels}\")\n",
        "\n",
        "# Step 2: Split the data into train and test sets\n",
        "# You can adjust the test_size parameter to control the ratio\n",
        "train_data, test_data = train_test_split(csv_file, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Save the train and test DataFrames to separate CSV files\n",
        "train_csv_file = 'train_file6.csv'\n",
        "test_csv_file = 'test_file6.csv'\n",
        "\n",
        "train_data.to_csv(train_csv_file, index=False)\n",
        "test_data.to_csv(test_csv_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oBtJBEjg1aAP",
        "outputId": "6d7f45ba-5349-4cac-f433-470286ced7fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8d47d4b-754f-4e06-a7f7-6845288000e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3204</td>\n",
              "      <td>3</td>\n",
              "      <td>agree the poor in india are treated badly thei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1431</td>\n",
              "      <td>2</td>\n",
              "      <td>if only i could have spent the with this cutie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>654</td>\n",
              "      <td>2</td>\n",
              "      <td>will nature conservation remain a priority in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2530</td>\n",
              "      <td>3</td>\n",
              "      <td>coronavirus disappearing in italy show this to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2296</td>\n",
              "      <td>3</td>\n",
              "      <td>uk records lowest daily virus death toll since...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3085</th>\n",
              "      <td>2579</td>\n",
              "      <td>3</td>\n",
              "      <td>today at 02 30pm a 54 year old bangladeshi mal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3086</th>\n",
              "      <td>3579</td>\n",
              "      <td>0</td>\n",
              "      <td>corona virus i implore that you cease activity...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3087</th>\n",
              "      <td>221</td>\n",
              "      <td>2</td>\n",
              "      <td>issa date once lockdown ends inshaallah (and c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3088</th>\n",
              "      <td>2705</td>\n",
              "      <td>3</td>\n",
              "      <td>the death toll due to covid 19 rose to 31 in j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3089</th>\n",
              "      <td>2962</td>\n",
              "      <td>3</td>\n",
              "      <td>the rates are become barrier for poor people t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3090 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8d47d4b-754f-4e06-a7f7-6845288000e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8d47d4b-754f-4e06-a7f7-6845288000e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8d47d4b-754f-4e06-a7f7-6845288000e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a4ab0f8-632e-4f5a-a477-6a71f52b2ea7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a4ab0f8-632e-4f5a-a477-6a71f52b2ea7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a4ab0f8-632e-4f5a-a477-6a71f52b2ea7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_efb3ce84-8c22-4091-9203-c2ce4061ea5e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('csv_file')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_efb3ce84-8c22-4091-9203-c2ce4061ea5e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('csv_file');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Unnamed: 0  sentiment                                               text\n",
              "0           3204          3  agree the poor in india are treated badly thei...\n",
              "1           1431          2  if only i could have spent the with this cutie...\n",
              "2            654          2  will nature conservation remain a priority in ...\n",
              "3           2530          3  coronavirus disappearing in italy show this to...\n",
              "4           2296          3  uk records lowest daily virus death toll since...\n",
              "...          ...        ...                                                ...\n",
              "3085        2579          3  today at 02 30pm a 54 year old bangladeshi mal...\n",
              "3086        3579          0  corona virus i implore that you cease activity...\n",
              "3087         221          2  issa date once lockdown ends inshaallah (and c...\n",
              "3088        2705          3  the death toll due to covid 19 rose to 31 in j...\n",
              "3089        2962          3  the rates are become barrier for poor people t...\n",
              "\n",
              "[3090 rows x 3 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkOWCqTe1Z9m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNDf5NsQ1Z6v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJpbUnfy1Z3n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QeVP7Pm1Z0j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO8D8e25q-uM"
      },
      "outputs": [],
      "source": [
        "print(\"y34423es\")\n",
        "\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "import psutil\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from evaluate import load as load_metric\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from transformers import logging\n",
        "\n",
        "\"\"\"Next we will set some global variables and disable some of the logging to clear out our output.\"\"\"\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "CHECKPOINT = \"albert-base-v2\"  # transformer model checkpoint\n",
        "NUM_CLIENTS = 10\n",
        "NUM_ROUNDS = 20\n",
        "\n",
        "\"\"\"## Standard Hugging Face workflow\n",
        "\n",
        "### Handling the data\n",
        "\n",
        "To fetch the IMDB dataset, we will use Hugging Face's `datasets` library. We then need to tokenize the data and create `PyTorch` dataloaders, this is all done in the `load_data` function:\n",
        "\"\"\"\n",
        "before_communication_cpu_percent = psutil.cpu_percent()\n",
        "current_process = psutil.Process()\n",
        "\n",
        "memory_info_after = current_process.memory_info()\n",
        "start = time.time()\n",
        "def load_data():\n",
        "    \"\"\"Load IMDB data (training and eval)\"\"\"\n",
        "    raw_datasets = load_dataset(\"cyrilzhang/financial_phrasebank_split\")#bhargavi909/medicaltransciptions\")\n",
        "    raw_datasets = raw_datasets.shuffle(seed=42)\n",
        "    # raw_datasets[\"train\"]['sentence'] = raw_datasets[\"train\"]['sentence'].apply(lambda x: x.ljust(200, 'x'))\n",
        "    # remove unnecessary data split\n",
        "    # del raw_datasets[\"unsupervised\"]\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        flat_list = [item for sublist in examples[\"sentence\"] for item in sublist]\n",
        "        return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=10)\n",
        "\n",
        "    # Select 20 random samples to reduce the computation cost\n",
        "    train_population = random.sample(range(len(raw_datasets[\"train\"])), 100)\n",
        "    test_population = random.sample(range(len(raw_datasets[\"test\"])), 100)\n",
        "\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "    tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].select(train_population)\n",
        "    tokenized_datasets[\"test\"] = tokenized_datasets[\"test\"].select(test_population)\n",
        "\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(\"sentence\")\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    trainloader = DataLoader(\n",
        "        tokenized_datasets[\"train\"],\n",
        "        shuffle=True,\n",
        "        batch_size=32,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "    testloader = DataLoader(\n",
        "        tokenized_datasets[\"test\"],\n",
        "        shuffle=True,\n",
        "        batch_size=32,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "\n",
        "    # testloader = DataLoader(\n",
        "    #     tokenized_datasets[\"test\"], batch_size=32, collate_fn=data_collator\n",
        "    # )\n",
        "    return trainloader, testloader,train_population,train_population\n",
        "\n",
        "\"\"\"### Training and testing the model\n",
        "\n",
        "Once we have a way of creating our trainloader and testloader, we can take care of the training and testing. This is very similar to any `PyTorch` training or testing loop:\n",
        "\"\"\"\n",
        "\n",
        "def train(net, trainloader, epochs):\n",
        "    optimizer = AdamW(net.parameters(), lr=5e-5)\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "            outputs = net(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    metric = load_metric(\"accuracy\")\n",
        "    loss = 0\n",
        "    net.eval()\n",
        "    for batch in testloader:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = net(**batch)\n",
        "        logits = outputs.logits\n",
        "        loss += outputs.loss.item()\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = metric.compute()[\"accuracy\"]\n",
        "    return loss, accuracy\n",
        "\n",
        "\"\"\"### Creating the model itself\n",
        "\n",
        "To create the model itself, we will just load the pre-trained alBERT model using Hugging Face’s `AutoModelForSequenceClassification` :\n",
        "\"\"\"\n",
        "\n",
        "net = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CHECKPOINT, num_labels=3\n",
        ").to(DEVICE)\n",
        "\n",
        "\"\"\"## Federating the example\n",
        "\n",
        "The idea behind Federated Learning is to train a model between multiple clients and a server without having to share any data. This is done by letting each client train the model locally on its data and send its parameters back to the server, which then aggregates all the clients’ parameters together using a predefined strategy. This process is made very simple by using the [Flower](https://github.com/adap/flower) framework. If you want a more complete overview, be sure to check out this guide: [What is Federated Learning?](https://flower.dev/docs/tutorial/Flower-0-What-is-FL.html)\n",
        "\n",
        "### Creating the IMDBClient\n",
        "\n",
        "To federate our example to multiple clients, we first need to write our Flower client class (inheriting from `flwr.client.NumPyClient`). This is very easy, as our model is a standard `PyTorch` model:\n",
        "\"\"\"\n",
        "\n",
        "class IMDBClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, testloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        self.net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        print(\"Training Started...\")\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        print(\"Training Finished.\")\n",
        "        return self.get_parameters(config={}), len(self.trainloader), {}\n",
        "    def train_model(self):\n",
        "        \"\"\"Train the model.\"\"\"\n",
        "        optimizer = AdamW(self.net.parameters(), lr=5e-5)\n",
        "        self.net.train()\n",
        "        for _ in range(1):  # Assuming 1 epoch for simplicity\n",
        "            for batch in self.trainloader:\n",
        "                batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "                # print(**batch)\n",
        "                outputs = self.net(**batch)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.net, self.testloader)\n",
        "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy), \"loss\": float(loss)}\n",
        "    def evaluate_model(self):\n",
        "        \"\"\"Evaluate the model.\"\"\"\n",
        "        metric = load_metric(\"accuracy\")\n",
        "        total_loss = 0\n",
        "        self.net.eval()\n",
        "        for batch in self.testloader:\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "            with torch.no_grad():\n",
        "                outputs = self.net(**batch)\n",
        "            logits = outputs.logits\n",
        "            total_loss += outputs.loss.item()\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "        total_loss /= len(self.testloader.dataset)\n",
        "        accuracy = metric.compute()[\"accuracy\"]\n",
        "        return total_loss, accuracy\n",
        "\n",
        "\"\"\"The `get_parameters` function lets the server get the client's parameters. Inversely, the `set_parameters` function allows the server to send its parameters to the client. Finally, the `fit` function trains the model locally for the client, and the `evaluate` function tests the model locally and returns the relevant metrics.\n",
        "\n",
        "### Generating the clients\n",
        "\n",
        "In order to simulate the federated setting we need to provide a way to instantiate clients for our simulation. Here, it is very simple as every client will hold the same piece of data (this is not realistic, it is just used here for simplicity sakes).\n",
        "\"\"\"\n",
        "\n",
        "trainloader, testloader,train_population,test_population = load_data()\n",
        "def client_fn(cid):\n",
        "  return IMDBClient(net, trainloader, testloader)\n",
        "\n",
        "\"\"\"## Starting the simulation\n",
        "\n",
        "We now have all the elements to start our simulation. The `weighted_average` function is there to provide a way to aggregate the metrics distributed amongst the clients (basically to display a nice average accuracy at the end of the training). We then define our strategy (here `FedAvg`, which will aggregate the clients weights by doing an average).\n",
        "\n",
        "Finally, `start_simulation` is used to start the training.\n",
        "\"\"\"\n",
        "\n",
        "def weighted_average1(metrics):\n",
        "  accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "  losses = [num_examples * m[\"loss\"] for num_examples, m in metrics]\n",
        "  examples = [num_examples for num_examples, _ in metrics]\n",
        "  return {\"accuracy\": sum(accuracies) / sum(examples), \"loss\": sum(losses) / sum(examples)}\n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average1,\n",
        ")\n",
        "\n",
        "# fl.simulation.start_simulation(\n",
        "#     client_fn=client_fn,\n",
        "#     num_clients=NUM_CLIENTS,\n",
        "#     config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
        "#     strategy=strategy,\n",
        "#     client_resources={\"num_cpus\": 1, \"num_gpus\": 0},\n",
        "#     ray_init_args={\"log_to_driver\": False, \"num_cpus\": 1, \"num_gpus\": 0}\n",
        "# )\n",
        "\n",
        "\"\"\"Note that this is a very basic example, and a lot can be added or modified, it was just to showcase how simply we could federate a Hugging Face workflow using Flower. The number of clients and the data samples are intentionally very small in order to quickly run inside Colab, but keep in mind that everything can be tweaked and extended.\"\"\"\n",
        "# ... (previous code)\n",
        "\n",
        "# Define a global model\n",
        "global_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CHECKPOINT, num_labels=5\n",
        ").to(DEVICE)\n",
        "def evaluate_global_model(global_model, testloader):\n",
        "    global_model.eval()\n",
        "    loss, accuracy = test(global_model, testloader)\n",
        "    return accuracy\n",
        "\n",
        "import copy\n",
        "\n",
        "global_model = copy.deepcopy(net)  # Create a copy of the initial model\n",
        "def evaluate_global_model(model, testloader):\n",
        "    \"\"\"Evaluate the global model on the test dataset.\"\"\"\n",
        "    loss, accuracy = test(model, testloader)\n",
        "    return accuracy\n",
        "\n",
        "# Define the global model for evaluation\n",
        "global_model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=3).to(DEVICE)\n",
        "strategy=strategy,\n",
        "trained_data = []\n",
        "tested_data = []\n",
        "global_model_Accuracies = []\n",
        "\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    aggregated_params = []\n",
        "    for _ in range(NUM_CLIENTS):\n",
        "        trainloader, testloader,train_population,test_population = load_data()\n",
        "        trained_data.append(train_population)\n",
        "        tested_data.append(test_population)\n",
        "        client = IMDBClient(global_model, trainloader, testloader)\n",
        "        client.train_model()\n",
        "        client_params = client.get_parameters(config={})\n",
        "        loss, accuracy = client.evaluate_model()\n",
        "        print(\"local_accuracy\"+\" :\" + str(accuracy))\n",
        "        aggregated_params.append(client_params)\n",
        "\n",
        "    # Averaging the parameters\n",
        "    avg_params = [sum(param) / len(param) for param in zip(*aggregated_params)]\n",
        "    global_model.load_state_dict(OrderedDict({k: torch.Tensor(v) for k, v in zip(global_model.state_dict().keys(), avg_params)}))\n",
        "\n",
        "    # Evaluate the global model\n",
        "    trainloader, testloader,train_population,test_population = load_data()\n",
        "    global_accuracy = evaluate_global_model(global_model, testloader)\n",
        "    global_model_Accuracies.append(global_accuracy)\n",
        "    print(f\"Global Model Accuracy: {global_accuracy * 100:.2f}%\")\n",
        "    global_model.save_pretrained('my_model.h5')\n",
        "    end = time.time()\n",
        "# Get the file size in GB\n",
        "    file_size = os.path.getsize('my_model.h5') / (1024 * 1024 * 1024)\n",
        "    print(f\"Model Size: {file_size} GB\")\n",
        "    print(f\"Latency: {(end-start)/60} min\")\n",
        "\n",
        "after_communication_cpu_percent = psutil.cpu_percent()\n",
        "current_process = psutil.Process()\n",
        "\n",
        "memory_info_before = current_process.memory_info()\n",
        "\n",
        "# Calculate the communication overhead\n",
        "cpu_overhead = after_communication_cpu_percent - before_communication_cpu_percent\n",
        "memory_overhead =(memory_info_after.rss - memory_info_before.rss) / (1024 ** 3)  # Convert bytes to GB\n",
        "\n",
        "print(f\"CPU Overhead: {cpu_overhead}%\")\n",
        "print(f\"Memory Usage: {memory_overhead:.2f} GB\")\n",
        "print(\"trained_data\")\n",
        "print(trained_data)\n",
        "print(\"tested_data\")\n",
        "print(tested_data)\n",
        "print(\"global_model_Accuracies\")\n",
        "print(global_model_Accuracies)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}