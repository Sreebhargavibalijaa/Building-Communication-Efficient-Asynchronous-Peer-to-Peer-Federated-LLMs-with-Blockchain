# -*- coding: utf-8 -*-
"""fl-with-flower.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/fl-with-flower.ipynb

# Federated Learning using Hugging Face and Flower

This tutorial will show how to leverage Hugging Face to federate the training of language models over multiple clients using [Flower](https://flower.dev/). More specifically, we will fine-tune a pre-trained Transformer model (alBERT) for sequence classification over a dataset of IMDB ratings. The end goal is to detect if a movie rating is positive or negative.

## Dependencies

For this tutorial we will need `datasets`, `flwr['simulation']`(here we use the extra 'simulation' dependencies from Flower as we will simulated the federated setting inside Google Colab), `torch`, and `transformers`.
"""


"""We can now import the relevant modules."""

from collections import OrderedDict
import os
import random
import warnings

import flwr as fl
import torch

from torch.utils.data import DataLoader

from datasets import load_dataset
from evaluate import load as load_metric

from transformers import AutoTokenizer, DataCollatorWithPadding
from transformers import AutoModelForSequenceClassification
from transformers import AdamW
from transformers import logging

"""Next we will set some global variables and disable some of the logging to clear out our output."""

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
logging.set_verbosity(logging.ERROR)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.simplefilter('ignore')

DEVICE = torch.device("cpu")
CHECKPOINT = "albert-base-v2"  # transformer model checkpoint
NUM_CLIENTS = 1
NUM_ROUNDS = 1

"""## Standard Hugging Face workflow

### Handling the data

To fetch the IMDB dataset, we will use Hugging Face's `datasets` library. We then need to tokenize the data and create `PyTorch` dataloaders, this is all done in the `load_data` function:
"""

def load_data():
    """Load IMDB data (training and eval)"""
    import pandas as pd
    df = pd.read_csv('/Users/sreebhargavibalija/Desktop/flower_self_driving_vehciles_fed_fineutnig/synthetic_reviews_ratings_self_driving_cars.csv')  # Replace with your CSV file path

    # Optionally preprocess the DataFrame
    # For example: df = df[['review', 'label']] if your columns are named as such

    # Step 2: Shuffle the DataFrame
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)

    # Tokenizer
    CHECKPOINT = "bert-base-uncased"  # Replace with your model checkpoint
    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)

    # Tokenization function
    def tokenize_function(examples):
        return tokenizer(examples["text"], truncation=True)

    # class IMDbDataset(Dataset):
    #     def __init__(self, encodings, labels):
    #         self.encodings = encodings
    #         self.labels = labels

    #     def __getitem__(self, idx):
    #         item = {key: val[idx] for key, val in self.encodings.items()}
    #         item["labels"] = self.labels[idx]
    #         return item

    #     def __len__(self):
    #         return len(self.labels)

    # Select 20 random samples for train and test
    train_population = random.sample(range(len(df)), 20)
    test_population = random.sample(range(len(df)), 20)

    # Preparing the datasets
    train_texts = df.iloc[train_population]["review"].tolist()
    train_labels = df.iloc[train_population]["label"].tolist()
    test_texts = df.iloc[test_population]["review"].tolist()
    test_labels = df.iloc[test_population]["label"].tolist()

    # Tokenize
    train_encodings = tokenizer(train_texts, truncation=True, padding=True)
    test_encodings = tokenizer(test_texts, truncation=True, padding=True)

    # Create custom datasets
    train_dataset = IMDbDataset(train_encodings, train_labels)
    test_dataset = IMDbDataset(test_encodings, test_labels)

    # Data collator
    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

    # DataLoaders
    trainloader = DataLoader(train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator)
    testloader = DataLoader(test_dataset, batch_size=32, collate_fn=data_collator)

"""### Training and testing the model

Once we have a way of creating our trainloader and testloader, we can take care of the training and testing. This is very similar to any `PyTorch` training or testing loop:
"""

def train(net, trainloader, epochs):
    optimizer = AdamW(net.parameters(), lr=5e-5)
    net.train()
    for _ in range(epochs):
        for batch in trainloader:
            batch = {k: v.to(DEVICE) for k, v in batch.items()}
            outputs = net(**batch)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()


def test(net, testloader):
    metric = load_metric("accuracy")
    loss = 0
    net.eval()
    for batch in testloader:
        batch = {k: v.to(DEVICE) for k, v in batch.items()}
        with torch.no_grad():
            outputs = net(**batch)
        logits = outputs.logits
        loss += outputs.loss.item()
        predictions = torch.argmax(logits, dim=-1)
        metric.add_batch(predictions=predictions, references=batch["labels"])
    loss /= len(testloader.dataset)
    accuracy = metric.compute()["accuracy"]
    return loss, accuracy

"""### Creating the model itself

To create the model itself, we will just load the pre-trained alBERT model using Hugging Face’s `AutoModelForSequenceClassification` :
"""

net = AutoModelForSequenceClassification.from_pretrained(
    CHECKPOINT, num_labels=2
).to(DEVICE)

"""## Federating the example

The idea behind Federated Learning is to train a model between multiple clients and a server without having to share any data. This is done by letting each client train the model locally on its data and send its parameters back to the server, which then aggregates all the clients’ parameters together using a predefined strategy. This process is made very simple by using the [Flower](https://github.com/adap/flower) framework. If you want a more complete overview, be sure to check out this guide: [What is Federated Learning?](https://flower.dev/docs/tutorial/Flower-0-What-is-FL.html)

### Creating the IMDBClient

To federate our example to multiple clients, we first need to write our Flower client class (inheriting from `flwr.client.NumPyClient`). This is very easy, as our model is a standard `PyTorch` model:
"""

class IMDBClient(fl.client.NumPyClient):
    def __init__(self, net, trainloader, testloader):
        self.net = net
        self.trainloader = trainloader
        self.testloader = testloader

    def get_parameters(self, config):
        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]

    def set_parameters(self, parameters):
        params_dict = zip(self.net.state_dict().keys(), parameters)
        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})
        self.net.load_state_dict(state_dict, strict=True)

    def fit(self, parameters, config):
        self.set_parameters(parameters)
        print("Training Started...")
        train(self.net, self.trainloader, epochs=1)
        print("Training Finished.")
        return self.get_parameters(config={}), len(self.trainloader), {}

    def evaluate(self, parameters, config):
        self.set_parameters(parameters)
        loss, accuracy = test(self.net, self.testloader)
        return float(loss), len(self.testloader), {"accuracy": float(accuracy), "loss": float(loss)}

"""The `get_parameters` function lets the server get the client's parameters. Inversely, the `set_parameters` function allows the server to send its parameters to the client. Finally, the `fit` function trains the model locally for the client, and the `evaluate` function tests the model locally and returns the relevant metrics.

### Generating the clients

In order to simulate the federated setting we need to provide a way to instantiate clients for our simulation. Here, it is very simple as every client will hold the same piece of data (this is not realistic, it is just used here for simplicity sakes).
"""

trainloader, testloader = load_data()
def client_fn(cid):
  return IMDBClient(net, trainloader, testloader)

"""## Starting the simulation

We now have all the elements to start our simulation. The `weighted_average` function is there to provide a way to aggregate the metrics distributed amongst the clients (basically to display a nice average accuracy at the end of the training). We then define our strategy (here `FedAvg`, which will aggregate the clients weights by doing an average).

Finally, `start_simulation` is used to start the training.
"""

def weighted_average(metrics):
  accuracies = [num_examples * m["accuracy"] for num_examples, m in metrics]
  losses = [num_examples * m["loss"] for num_examples, m in metrics]
  examples = [num_examples for num_examples, _ in metrics]
  return {"accuracy": sum(accuracies) / sum(examples), "loss": sum(losses) / sum(examples)}

strategy = fl.server.strategy.FedAvg(
    fraction_fit=1.0,
    fraction_evaluate=1.0,
    evaluate_metrics_aggregation_fn=weighted_average,
)

# fl.simulation.start_simulation(
#     client_fn=client_fn,
#     num_clients=NUM_CLIENTS,
#     config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),
#     strategy=strategy,
#     client_resources={"num_cpus": 1, "num_gpus": 0},
#     ray_init_args={"log_to_driver": False, "num_cpus": 1, "num_gpus": 0}
# )

"""Note that this is a very basic example, and a lot can be added or modified, it was just to showcase how simply we could federate a Hugging Face workflow using Flower. The number of clients and the data samples are intentionally very small in order to quickly run inside Colab, but keep in mind that everything can be tweaked and extended."""
# ... (previous code)

# Define a global model
global_model = AutoModelForSequenceClassification.from_pretrained(
    CHECKPOINT, num_labels=2
).to(DEVICE)

# Define a function to update the global model using the averaged client parameters
def update_global_model(client_models):
    global_state_dict = global_model.state_dict()
    num_clients = len(client_models)

    for key in global_state_dict:
        # Initialize the sum of client parameters for each layer
        sum_layer_params = torch.zeros_like(global_state_dict[key])

        for client_model in client_models:
            sum_layer_params += client_model[key]

        # Average the client parameters
        global_state_dict[key] = sum_layer_params / num_clients

    global_model.load_state_dict(global_state_dict)
    return global_model
# ... (previous code)

# In the client's fit method, return the model parameters after training
def fit(self, parameters, config):
    self.set_parameters(parameters)
    print("Training Started...")
    train(self.net, self.trainloader, epochs=1)
    print("Training Finished.")
    
    # Return the trained client model parameters
    return self.get_parameters(config={}), len(self.trainloader), {}

# ... (previous code)

# Update the global model with averaged client parameters
def weighted_average(models):
    num_clients = len(models)
    averaged_models = []

    for i in range(len(models[0])):
        # Initialize the sum of client parameters for each layer
        sum_layer_params = torch.zeros_like(models[0][i])

        for j in range(num_clients):
            sum_layer_params += models[j][i]

        # Average the client parameters
        averaged_layer_params = sum_layer_params / num_clients
        averaged_models.append(averaged_layer_params)

    global_model = update_global_model(averaged_models)

# ... (previous code)

# Define the federated learning strategy
# ... (previous code)

# Define a function to calculate accuracy for a single client
def calculate_client_accuracy(model, testloader):
    model.eval()
    metric = load_metric("accuracy")
    for batch in testloader:
        batch = {k: v.to(DEVICE) for k, v in batch.items()}
        with torch.no_grad():
            outputs = model(**batch)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        metric.add_batch(predictions=predictions, references=batch["labels"])
    accuracy = metric.compute()["accuracy"]
    return accuracy

# ... (previous code)

# In the client's evaluate method, return the accuracy
def evaluate(self, parameters, config):
    self.set_parameters(parameters)
    accuracy = calculate_client_accuracy(self.net, self.testloader)
    return float(accuracy), len(self.testloader), {"accuracy": float(accuracy)}

# ... (previous code)

# Define the federated learning strategy
strategy = fl.server.strategy.FedAvg(
    fraction_fit=1.0,
    fraction_evaluate=1.0,
    # evaluate_fn=lambda clients: sum([c[2]["accuracy"] for c in clients]) / len(clients),
    evaluate_metrics_aggregation_fn=weighted_average,
)

# ... (previous code)

# After the simulation, you can evaluate the global model on the test dataset
testloader = load_data()[1]  # Load the testloader
global_model.eval()
global_accuracy = calculate_client_accuracy(global_model, testloader)
print(f"Global Model Accuracy: {global_accuracy}")
fl.simulation.start_simulation(
    client_fn=client_fn,
    num_clients=NUM_CLIENTS,
    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),
    strategy=strategy,
    client_resources={"num_cpus": 1, "num_gpus": 0},
    ray_init_args={"log_to_driver": False, "num_cpus": 1, "num_gpus": 0})
